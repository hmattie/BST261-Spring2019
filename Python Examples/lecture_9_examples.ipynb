{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.2.4'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving RNN Performance and Generalizability\n",
    "\n",
    "In this notebook, we will review three advanced techniques for improving the performance and generalization power of recurrent neural networks. We will demonstrate all three concepts on a weather forecasting problem, where we have access to a timeseries of data points coming from sensors installed on the roof of a building, such as temperature, air pressure, and humidity, which we use to predict what the temperature will be 24 hours after the last data point collected. This is a fairly challenging problem that exemplifies many common difficulties encountered when working with timeseries.\n",
    "\n",
    "We will cover the following techniques:\n",
    "\n",
    "* *__Recurrent dropout__*, a specific, built-in way to use dropout to fight overfitting in recurrent layers.\n",
    "* *__Stacking recurrent layers__*, to increase the representational power of the network (at the cost of higher computational loads).\n",
    "* *__Bidirectional recurrent layers__*, which presents the same information to a recurrent network in different ways, increasing accuracy and \n",
    "mitigating forgetting issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A temperature forecasting problem\n",
    "\n",
    "Until now, the only sequence data we have covered has been text data, for instance the IMDb dataset. But sequence \n",
    "data is found in many more problems than just language processing. In all of our examples in this section, we will be playing with a weather timeseries dataset recorded at the Weather Station at the Max-Planck-Institute for Biogeochemistry in Jena, Germany: http://www.bgc-jena.mpg.de/wetter/.\n",
    "\n",
    "In this dataset, 14 different quantities (such air temperature, atmospheric pressure, humidity, wind direction, etc.) are recorded every 10 minutes, over several years. The original data goes back to 2003, but we limit ourselves to data from 2009-2016. This dataset is perfect for learning to work with numerical timeseries. We will use it to build a model that takes as input some data from the recent past (a few days worth of data points) and predicts the air temperature 24 hours in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\"Date Time\"', '\"p (mbar)\"', '\"T (degC)\"', '\"Tpot (K)\"', '\"Tdew (degC)\"', '\"rh (%)\"', '\"VPmax (mbar)\"', '\"VPact (mbar)\"', '\"VPdef (mbar)\"', '\"sh (g/kg)\"', '\"H2OC (mmol/mol)\"', '\"rho (g/m**3)\"', '\"wv (m/s)\"', '\"max. wv (m/s)\"', '\"wd (deg)\"']\n",
      "420551\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "fname = '/Users/heathermattie/Desktop/jena_climate_2009_2016.csv'\n",
    "f = open(fname)\n",
    "data = f.read()\n",
    "f.close()\n",
    "\n",
    "lines = data.split('\\n')     # Each line is 1 recording\n",
    "header = lines[0].split(',') # Variable names are separated by commas\n",
    "lines = lines[1:]            # Drop first line (it's a header)\n",
    "\n",
    "print(header)\n",
    "print(len(lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's convert all of these 420,551 lines of data into a Numpy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(420551, 14)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "float_data = np.zeros((len(lines), len(header) - 1))\n",
    "for i, line in enumerate(lines):\n",
    "    values = [float(x) for x in line.split(',')[1:]]\n",
    "    float_data[i, :] = values\n",
    "print(float_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance, here is the plot of temperature (in degrees Celsius) over time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0xb4af877f0>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "temp = float_data[:, 1]  # temperature (in degrees Celsius)\n",
    "plt.plot(range(len(temp)), temp)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "On this plot, you can clearly see the yearly periodicity of temperature.\n",
    "\n",
    "Here is a more narrow plot of the first ten days of temperature data (since the data is recorded every ten minutes, we get 144 data points \n",
    "per day):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1440), temp[:1440])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "On this plot, you can see daily periodicity, especially evident for the last 4 days. We can also note that this ten-days period must be \n",
    "coming from a fairly cold winter month.\n",
    "\n",
    "If we were trying to predict average temperature for the next month given a few month of past data, the problem would be easy, due to the \n",
    "reliable year-scale periodicity of the data. But looking at the data over a scale of days, the temperature looks a lot more chaotic. So is \n",
    "this timeseries predictable at a daily scale? Let's find out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data\n",
    "\n",
    "\n",
    "The exact formulation of our problem will be the following: given data going as far back as `lookback` timesteps (a timestep is 10 minutes) \n",
    "and sampled every `steps` timesteps, can we predict the temperature in `delay` timesteps?\n",
    "\n",
    "We will use the following parameter values:\n",
    "\n",
    "* `lookback = 1440`, i.e. our observations will go back 10 days.\n",
    "* `steps = 6`, i.e. our observations will be sampled at one data point per hour.\n",
    "* `delay = 144`, i.e. our targets will be 24 hours in the future.\n",
    "\n",
    "To get started, we need to do two things:\n",
    "\n",
    "* Preprocess the data to a format a neural network can ingest. This is easy: the data is already numerical, so we don't need to do any \n",
    "vectorization. However each timeseries in the data is on a different scale (e.g. temperature is typically between -20 and +30, but \n",
    "pressure, measured in mbar, is around 1000). So we will normalize each timeseries independently so that they all take small values on a \n",
    "similar scale.\n",
    "* Write a Python generator that takes our current array of float data and yields batches of data from the recent past, alongside with a \n",
    "target temperature in the future. Since the samples in our dataset are highly redundant (e.g. sample `N` and sample `N + 1` will have most \n",
    "of their timesteps in common), it would be very wasteful to explicitly allocate every sample. Instead, we will generate the samples on the \n",
    "fly using the original data.\n",
    "\n",
    "We preprocess the data by subtracting the mean of each timeseries and dividing by the standard deviation. We plan on using the first \n",
    "200,000 timesteps as training data, so we compute the mean and standard deviation only on this fraction of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean = float_data[:200000].mean(axis=0)\n",
    "float_data -= mean\n",
    "std = float_data[:200000].std(axis=0)\n",
    "float_data /= std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now here is the data generator that we will use. It yields a tuple `(samples, targets)` where `samples` is one batch of input data and \n",
    "`targets` is the corresponding array of target temperatures. It takes the following arguments:\n",
    "\n",
    "* `data`: The original array of floating point data, which we just normalized in the code snippet above.\n",
    "* `lookback`: How many timesteps back should our input data go.\n",
    "* `delay`: How many timesteps in the future should our target be.\n",
    "* `min_index` and `max_index`: Indices in the `data` array that delimit which timesteps to draw from. This is useful for keeping a segment \n",
    "of the data for validation and another one for testing.\n",
    "* `shuffle`: Whether to shuffle our samples or draw them in chronological order.\n",
    "* `batch_size`: The number of samples per batch.\n",
    "* `step`: The period, in timesteps, at which we sample data. We will set it 6 in order to draw one data point every hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(data, lookback, delay, min_index, max_index,\n",
    "              shuffle=False, batch_size=128, step=6):\n",
    "    if max_index is None:\n",
    "        max_index = len(data) - delay - 1\n",
    "    i = min_index + lookback\n",
    "    while 1:\n",
    "        if shuffle:\n",
    "            rows = np.random.randint(\n",
    "                min_index + lookback, max_index, size=batch_size)\n",
    "        else:\n",
    "            if i + batch_size >= max_index:\n",
    "                i = min_index + lookback\n",
    "            rows = np.arange(i, min(i + batch_size, max_index))\n",
    "            i += len(rows)\n",
    "\n",
    "        samples = np.zeros((len(rows),\n",
    "                           lookback // step,\n",
    "                           data.shape[-1]))\n",
    "        targets = np.zeros((len(rows),))\n",
    "        for j, row in enumerate(rows):\n",
    "            indices = range(rows[j] - lookback, rows[j], step)\n",
    "            samples[j] = data[indices]\n",
    "            targets[j] = data[rows[j] + delay][1]\n",
    "        yield samples, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now let's use our abstract generator function to instantiate three generators, one for training, one for validation and one for testing. \n",
    "Each will look at different temporal segments of the original data: the training generator looks at the first 200,000 timesteps, the \n",
    "validation generator looks at the following 100,000, and the test generator looks at the remainder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "769\n",
      "930\n"
     ]
    }
   ],
   "source": [
    "lookback = 1440\n",
    "step = 6\n",
    "delay = 144\n",
    "batch_size = 128\n",
    "\n",
    "train_gen = generator(float_data,\n",
    "                      lookback=lookback,\n",
    "                      delay=delay,\n",
    "                      min_index=0,\n",
    "                      max_index=200000,\n",
    "                      shuffle=True,\n",
    "                      step=step, \n",
    "                      batch_size=batch_size)\n",
    "val_gen = generator(float_data,\n",
    "                    lookback=lookback,\n",
    "                    delay=delay,\n",
    "                    min_index=200001,\n",
    "                    max_index=300000,\n",
    "                    step=step,\n",
    "                    batch_size=batch_size)\n",
    "test_gen = generator(float_data,\n",
    "                     lookback=lookback,\n",
    "                     delay=delay,\n",
    "                     min_index=300001,\n",
    "                     max_index=None,\n",
    "                     step=step,\n",
    "                     batch_size=batch_size)\n",
    "\n",
    "# This is how many steps to draw from `val_gen`\n",
    "# in order to see the whole validation set:\n",
    "val_steps = (300000 - 200001 - lookback) // batch_size\n",
    "\n",
    "# This is how many steps to draw from `test_gen`\n",
    "# in order to see the whole test set:\n",
    "test_steps = (len(float_data) - 300001 - lookback) // batch_size\n",
    "\n",
    "print(val_steps)\n",
    "print(test_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A common sense, non-machine learning baseline\n",
    "\n",
    "\n",
    "Before we start leveraging black-box deep learning models to solve our temperature prediction problem, let's try out a simple common-sense \n",
    "approach. It will serve as a sanity check, and it will establish a baseline that we will have to beat in order to demonstrate the \n",
    "usefulness of more advanced machine learning models. Such common-sense baselines can be very useful when approaching a new problem for \n",
    "which there is no known solution (yet). A classic example is that of unbalanced classification tasks, where some classes can be much more \n",
    "common than others. If your dataset contains 90% of instances of class A and 10% of instances of class B, then a common sense approach to \n",
    "the classification task would be to always predict \"A\" when presented with a new sample. Such a classifier would be 90% accurate overall, \n",
    "and any learning-based approach should therefore beat this 90% score in order to demonstrate usefulness. Sometimes such elementary \n",
    "baseline can prove surprisingly hard to beat.\n",
    "\n",
    "In our case, the temperature timeseries can safely be assumed to be continuous (the temperatures tomorrow are likely to be close to the \n",
    "temperatures today) as well as periodical with a daily period. Thus a common sense approach would be to always predict that the temperature \n",
    "24 hours from now will be equal to the temperature right now. Let's evaluate this approach, using the Mean Absolute Error metric (MAE). \n",
    "Mean Absolute Error is simply equal to `mean(abs(predictions - targets))`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's our evaluation loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2897359729905486\n"
     ]
    }
   ],
   "source": [
    "def evaluate_naive_method():\n",
    "    batch_maes = []\n",
    "    for step in range(val_steps):\n",
    "        samples, targets = next(val_gen)\n",
    "        preds = samples[:, -1, 1]\n",
    "        mae = np.mean(np.abs(preds - targets))\n",
    "        batch_maes.append(mae)\n",
    "    print(np.mean(batch_maes))\n",
    "    \n",
    "evaluate_naive_method()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It yields a MAE of 0.29. Since our temperature data has been normalized to be centered on 0 and have a standard deviation of one, this \n",
    "number is not immediately interpretable. It translates to an average absolute error of `0.29 * temperature_std` degrees Celsius, i.e. \n",
    "2.57˚C. That's a fairly large average absolute error -- now the game is to leverage our knowledge of deep learning to do better. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A basic machine learning approach\n",
    "\n",
    "In the same way that it is useful to establish a common sense baseline before trying machine learning approaches, it is useful to try \n",
    "simple and cheap machine learning models (such as small densely-connected networks) before looking into complicated and computationally \n",
    "expensive models such as RNNs. This is the best way to make sure that any further complexity we throw at the problem later on is legitimate \n",
    "and delivers real benefits.\n",
    "\n",
    "Here is a simply fully-connected model in which we start by flattening the data, then run it through two `Dense` layers. Note the lack of \n",
    "activation function on the last `Dense` layer, which is typical for a regression problem. We use MAE as the loss. Since we are evaluating \n",
    "on the exact same data and with the exact same metric as with our common sense approach, the results will be directly comparable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/heathermattie/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/heathermattie/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/20\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Flatten(input_shape=(lookback // step, float_data.shape[-1])))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(1))\n",
    "\n",
    "model.compile(optimizer=RMSprop(), loss='mae')\n",
    "history = model.fit_generator(train_gen,\n",
    "                              steps_per_epoch=500,\n",
    "                              epochs=20,\n",
    "                              validation_data=val_gen,\n",
    "                              validation_steps=val_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's display the loss curves for validation and training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3317e5a2b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njSjpi4ikkf8PQHVe3fAN/ToAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3317ee2e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(loss))\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Some of our validation losses get close to the no-learning baseline, but not very reliably. This goes to show the merit of having had this baseline in the first place: it turns out not to be so easy to outperform. Our \n",
    "common sense contains already a lot of valuable information that a machine learning model does not have access to.\n",
    "\n",
    "You may ask, if there exists a simple, well-performing model to go from the data to the targets (our common sense baseline), why doesn't \n",
    "the model we are training find it and improve on it? Simply put: because this simple solution is not what our training setup is looking \n",
    "for. The space of models in which we are searching for a solution, i.e. our hypothesis space, is the space of all possible 2-layer networks \n",
    "with the configuration that we defined. These networks are already fairly complicated. When looking for a solution with a space of \n",
    "complicated models, the simple well-performing baseline might be unlearnable, even if it's technically part of the hypothesis space. That \n",
    "is a pretty significant limitation of machine learning in general: unless the learning algorithm is hard-coded to look for a specific kind \n",
    "of simple model, parameter learning can sometimes fail to find a simple solution to a simple problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A first recurrent baseline\n",
    "\n",
    "\n",
    "Our first fully-connected approach didn't do so well, but that doesn't mean machine learning is not applicable to our problem. The approach \n",
    "above consisted in first flattening the timeseries, which removed the notion of time from the input data. Let us instead look at our data \n",
    "as what it is: a sequence, where causality and order matter. We will try a recurrent sequence processing model -- it should be the perfect \n",
    "fit for such sequence data, precisely because it does exploit the temporal ordering of data points, unlike our first approach.\n",
    "\n",
    "Instead of the `LSTM` layer introduced in the previous section, we will use the `GRU` layer, developed by Cho et al. in 2014. `GRU` layers \n",
    "(which stands for \"gated recurrent unit\") work by leveraging the same principle as LSTM, but they are somewhat streamlined and thus cheaper \n",
    "to run, albeit they may not have quite as much representational power as LSTM. This trade-off between computational expensiveness and \n",
    "representational power is seen everywhere in machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_2 (GRU)                  (None, 32)                4512      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 4,545\n",
      "Trainable params: 4,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "500/500 [==============================] - 236s 471ms/step - loss: 0.2997 - val_loss: 0.274\n",
      "Epoch 2/20\n",
      "500/500 [==============================] - 233s 466ms/step - loss: 0.2841 - val_loss: 0.26\n",
      "Epoch 3/20\n",
      "500/500 [==============================] - 233s 466ms/step - loss: 0.2760 - val_loss: 0.267\n",
      "Epoch 4/20\n",
      "500/500 [==============================] - 252s 505ms/step - loss: 0.2727 - val_loss: 0.261\n",
      "Epoch 5/20\n",
      "415/500 [=======================>......] - ETA: 36s - loss: 0.2687"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-114de9ab0c71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m                               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                               validation_steps=val_steps)\n\u001b[0m",
      "\u001b[0;32m/Users/heathermattie/anaconda/lib/python3.5/site-packages/Keras-2.1.4-py3.5.egg/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/heathermattie/anaconda/lib/python3.5/site-packages/Keras-2.1.4-py3.5.egg/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1251\u001b[0m                                         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1252\u001b[0m                                         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1253\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1255\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/heathermattie/anaconda/lib/python3.5/site-packages/Keras-2.1.4-py3.5.egg/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/heathermattie/anaconda/lib/python3.5/site-packages/Keras-2.1.4-py3.5.egg/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2235\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2236\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2237\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2239\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/heathermattie/anaconda/lib/python3.5/site-packages/Keras-2.1.4-py3.5.egg/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1881\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1883\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1884\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1885\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/heathermattie/anaconda/lib/python3.5/site-packages/Keras-2.1.4-py3.5.egg/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/heathermattie/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/heathermattie/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/heathermattie/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/heathermattie/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/heathermattie/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.GRU(32, input_shape=(None, float_data.shape[-1])))\n",
    "model.add(layers.Dense(1))\n",
    "print(model.summary())\n",
    "model.compile(optimizer=RMSprop(), loss='mae')\n",
    "history = model.fit_generator(train_gen,\n",
    "                              steps_per_epoch=500,\n",
    "                              epochs=20,\n",
    "                              validation_data=val_gen,\n",
    "                              validation_steps=val_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let look at our results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3317e755f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkr6ISBZR0hcRySL/H5V5hnuyqMOlAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3316a8b358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(loss))\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Much better! We are able to significantly beat the common sense baseline, such demonstrating the value of machine learning here, as well as \n",
    "the superiority of recurrent networks compared to sequence-flattening dense networks on this type of task.\n",
    "\n",
    "Our new validation MAE of ~0.265 (before we start significantly overfitting) translates to a mean absolute error of 2.35˚C after \n",
    "de-normalization. That's a solid gain on our initial error of 2.57˚C, but we probably still have a bit of margin for improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using recurrent dropout to fight overfitting\n",
    "\n",
    "\n",
    "It is evident from our training and validation curves that our model is overfitting: the training and validation losses start diverging \n",
    "considerably after a few epochs. You are already familiar with a classic technique for fighting this phenomenon: dropout, consisting in \n",
    "randomly zeroing-out input units of a layer in order to break happenstance correlations in the training data that the layer is exposed to. \n",
    "How to correctly apply dropout in recurrent networks, however, is not a trivial question. It has long been known that applying dropout \n",
    "before a recurrent layer hinders learning rather than helping with regularization. In 2015, Yarin Gal, as part of his Ph.D. thesis on \n",
    "Bayesian deep learning, determined the proper way to use dropout with a recurrent network: the same dropout mask (the same pattern of \n",
    "dropped units) should be applied at every timestep, instead of a dropout mask that would vary randomly from timestep to timestep. What's \n",
    "more: in order to regularize the representations formed by the recurrent gates of layers such as GRU and LSTM, a temporally constant \n",
    "dropout mask should be applied to the inner recurrent activations of the layer (a \"recurrent\" dropout mask). Using the same dropout mask at \n",
    "every timestep allows the network to properly propagate its learning error through time; a temporally random dropout mask would instead \n",
    "disrupt this error signal and be harmful to the learning process.\n",
    "\n",
    "Yarin Gal did his research using Keras and helped build this mechanism directly into Keras recurrent layers. Every recurrent layer in Keras \n",
    "has two dropout-related arguments: `dropout`, a float specifying the dropout rate for input units of the layer, and `recurrent_dropout`, \n",
    "specifying the dropout rate of the recurrent units. Let's add dropout and recurrent dropout to our GRU layer and see how it impacts \n",
    "overfitting. Because networks being regularized with dropout always take longer to fully converge, we train our network for twice as many \n",
    "epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "500/500 [==============================] - 171s - loss: 0.3526 - val_loss: 0.2740\n",
      "Epoch 2/40\n",
      "500/500 [==============================] - 170s - loss: 0.3138 - val_loss: 0.2742\n",
      "Epoch 3/40\n",
      "500/500 [==============================] - 170s - loss: 0.3065 - val_loss: 0.2692\n",
      "Epoch 4/40\n",
      "500/500 [==============================] - 170s - loss: 0.3033 - val_loss: 0.2694\n",
      "Epoch 5/40\n",
      "500/500 [==============================] - 170s - loss: 0.3006 - val_loss: 0.2695\n",
      "Epoch 6/40\n",
      "500/500 [==============================] - 170s - loss: 0.2990 - val_loss: 0.2709\n",
      "Epoch 7/40\n",
      "500/500 [==============================] - 170s - loss: 0.2955 - val_loss: 0.2667\n",
      "Epoch 8/40\n",
      "500/500 [==============================] - 170s - loss: 0.2942 - val_loss: 0.2671\n",
      "Epoch 9/40\n",
      "500/500 [==============================] - 171s - loss: 0.2940 - val_loss: 0.2649\n",
      "Epoch 10/40\n",
      "500/500 [==============================] - 170s - loss: 0.2923 - val_loss: 0.2673\n",
      "Epoch 11/40\n",
      "500/500 [==============================] - 170s - loss: 0.2894 - val_loss: 0.2695\n",
      "Epoch 12/40\n",
      "500/500 [==============================] - 170s - loss: 0.2899 - val_loss: 0.2648\n",
      "Epoch 13/40\n",
      "500/500 [==============================] - 170s - loss: 0.2879 - val_loss: 0.2634\n",
      "Epoch 14/40\n",
      "500/500 [==============================] - 170s - loss: 0.2884 - val_loss: 0.2666\n",
      "Epoch 15/40\n",
      "500/500 [==============================] - 170s - loss: 0.2863 - val_loss: 0.2695\n",
      "Epoch 16/40\n",
      "500/500 [==============================] - 170s - loss: 0.2852 - val_loss: 0.2705\n",
      "Epoch 17/40\n",
      "500/500 [==============================] - 170s - loss: 0.2843 - val_loss: 0.2739\n",
      "Epoch 18/40\n",
      "500/500 [==============================] - 170s - loss: 0.2844 - val_loss: 0.2646\n",
      "Epoch 19/40\n",
      "500/500 [==============================] - 170s - loss: 0.2827 - val_loss: 0.2661\n",
      "Epoch 20/40\n",
      "500/500 [==============================] - 170s - loss: 0.2813 - val_loss: 0.2637\n",
      "Epoch 21/40\n",
      "500/500 [==============================] - 170s - loss: 0.2805 - val_loss: 0.2663\n",
      "Epoch 22/40\n",
      "500/500 [==============================] - 170s - loss: 0.2786 - val_loss: 0.2662\n",
      "Epoch 23/40\n",
      "500/500 [==============================] - 170s - loss: 0.2795 - val_loss: 0.2637\n",
      "Epoch 24/40\n",
      "500/500 [==============================] - 170s - loss: 0.2801 - val_loss: 0.2649\n",
      "Epoch 25/40\n",
      "500/500 [==============================] - 170s - loss: 0.2774 - val_loss: 0.2723\n",
      "Epoch 26/40\n",
      "500/500 [==============================] - 170s - loss: 0.2788 - val_loss: 0.2682\n",
      "Epoch 27/40\n",
      "500/500 [==============================] - 171s - loss: 0.2780 - val_loss: 0.2655\n",
      "Epoch 28/40\n",
      "500/500 [==============================] - 170s - loss: 0.2782 - val_loss: 0.2645\n",
      "Epoch 29/40\n",
      "500/500 [==============================] - 170s - loss: 0.2770 - val_loss: 0.2647\n",
      "Epoch 30/40\n",
      "500/500 [==============================] - 170s - loss: 0.2756 - val_loss: 0.2746\n",
      "Epoch 31/40\n",
      "500/500 [==============================] - 171s - loss: 0.2763 - val_loss: 0.2641\n",
      "Epoch 32/40\n",
      "500/500 [==============================] - 170s - loss: 0.2752 - val_loss: 0.2733\n",
      "Epoch 33/40\n",
      "500/500 [==============================] - 170s - loss: 0.2742 - val_loss: 0.2619\n",
      "Epoch 34/40\n",
      "500/500 [==============================] - 170s - loss: 0.2753 - val_loss: 0.2711\n",
      "Epoch 35/40\n",
      "500/500 [==============================] - 170s - loss: 0.2727 - val_loss: 0.2658\n",
      "Epoch 36/40\n",
      "500/500 [==============================] - 170s - loss: 0.2724 - val_loss: 0.2664\n",
      "Epoch 37/40\n",
      "500/500 [==============================] - 170s - loss: 0.2725 - val_loss: 0.2661\n",
      "Epoch 38/40\n",
      "500/500 [==============================] - 171s - loss: 0.2725 - val_loss: 0.2633\n",
      "Epoch 39/40\n",
      "500/500 [==============================] - 170s - loss: 0.2726 - val_loss: 0.2695\n",
      "Epoch 40/40\n",
      "500/500 [==============================] - 170s - loss: 0.2727 - val_loss: 0.2719\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.GRU(32,\n",
    "                     dropout=0.2,\n",
    "                     recurrent_dropout=0.2,\n",
    "                     input_shape=(None, float_data.shape[-1])))\n",
    "model.add(layers.Dense(1))\n",
    "\n",
    "model.compile(optimizer=RMSprop(), loss='mae')\n",
    "history = model.fit_generator(train_gen,\n",
    "                              steps_per_epoch=500,\n",
    "                              epochs=40,\n",
    "                              validation_data=val_gen,\n",
    "                              validation_steps=val_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3317e879e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+f9aLqARS41G2QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3315076e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(loss))\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great success; we are no longer overfitting during the first 30 epochs. However, while we have more stable evaluation scores, our best \n",
    "scores are not much lower than they were previously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking recurrent layers\n",
    "\n",
    "Since we are no longer overfitting yet we seem to have hit a performance bottleneck, we should start considering increasing the capacity of \n",
    "our network. If you remember our description of the \"universal machine learning workflow\": it is a generally a good idea to increase the \n",
    "capacity of your network until overfitting becomes your primary obstacle (assuming that you are already taking basic steps to mitigate \n",
    "overfitting, such as using dropout). As long as you are not overfitting too badly, then you are likely under-capacity.\n",
    "\n",
    "Increasing network capacity is typically done by increasing the number of units in the layers, or adding more layers. Recurrent layer \n",
    "stacking is a classic way to build more powerful recurrent networks: for instance, what currently powers the Google translate algorithm is \n",
    "a stack of seven large LSTM layers -- that's huge.\n",
    "\n",
    "To stack recurrent layers on top of each other in Keras, all intermediate layers should return their full sequence of outputs (a 3D tensor) \n",
    "rather than their output at the last timestep. This is done by specifying `return_sequences=True`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "500/500 [==============================] - 346s - loss: 0.3341 - val_loss: 0.2780\n",
      "Epoch 2/40\n",
      "500/500 [==============================] - 344s - loss: 0.3125 - val_loss: 0.2754\n",
      "Epoch 3/40\n",
      "500/500 [==============================] - 344s - loss: 0.3045 - val_loss: 0.2696\n",
      "Epoch 4/40\n",
      "500/500 [==============================] - 344s - loss: 0.3018 - val_loss: 0.2747\n",
      "Epoch 5/40\n",
      "500/500 [==============================] - 344s - loss: 0.2957 - val_loss: 0.2690\n",
      "Epoch 6/40\n",
      "500/500 [==============================] - 344s - loss: 0.2923 - val_loss: 0.2692\n",
      "Epoch 7/40\n",
      "500/500 [==============================] - 344s - loss: 0.2907 - val_loss: 0.2673\n",
      "Epoch 8/40\n",
      "500/500 [==============================] - 343s - loss: 0.2879 - val_loss: 0.2690\n",
      "Epoch 9/40\n",
      "500/500 [==============================] - 343s - loss: 0.2866 - val_loss: 0.2743\n",
      "Epoch 10/40\n",
      "500/500 [==============================] - 344s - loss: 0.2833 - val_loss: 0.2669\n",
      "Epoch 11/40\n",
      "500/500 [==============================] - 344s - loss: 0.2825 - val_loss: 0.2669\n",
      "Epoch 12/40\n",
      "500/500 [==============================] - 344s - loss: 0.2822 - val_loss: 0.2700\n",
      "Epoch 13/40\n",
      "500/500 [==============================] - 345s - loss: 0.2785 - val_loss: 0.2698\n",
      "Epoch 14/40\n",
      "500/500 [==============================] - 345s - loss: 0.2775 - val_loss: 0.2634\n",
      "Epoch 15/40\n",
      "500/500 [==============================] - 344s - loss: 0.2778 - val_loss: 0.2653\n",
      "Epoch 16/40\n",
      "500/500 [==============================] - 344s - loss: 0.2740 - val_loss: 0.2633\n",
      "Epoch 17/40\n",
      "500/500 [==============================] - 344s - loss: 0.2746 - val_loss: 0.2680\n",
      "Epoch 18/40\n",
      "500/500 [==============================] - 344s - loss: 0.2731 - val_loss: 0.2649\n",
      "Epoch 19/40\n",
      "500/500 [==============================] - 345s - loss: 0.2709 - val_loss: 0.2699\n",
      "Epoch 20/40\n",
      "500/500 [==============================] - 344s - loss: 0.2693 - val_loss: 0.2655\n",
      "Epoch 21/40\n",
      "500/500 [==============================] - 345s - loss: 0.2679 - val_loss: 0.2654\n",
      "Epoch 22/40\n",
      "500/500 [==============================] - 344s - loss: 0.2677 - val_loss: 0.2731\n",
      "Epoch 23/40\n",
      "500/500 [==============================] - 345s - loss: 0.2672 - val_loss: 0.2680\n",
      "Epoch 24/40\n",
      "500/500 [==============================] - 345s - loss: 0.2648 - val_loss: 0.2669\n",
      "Epoch 25/40\n",
      "500/500 [==============================] - 345s - loss: 0.2645 - val_loss: 0.2655\n",
      "Epoch 26/40\n",
      "500/500 [==============================] - 344s - loss: 0.2648 - val_loss: 0.2673\n",
      "Epoch 27/40\n",
      "500/500 [==============================] - 344s - loss: 0.2624 - val_loss: 0.2694\n",
      "Epoch 28/40\n",
      "500/500 [==============================] - 344s - loss: 0.2624 - val_loss: 0.2698\n",
      "Epoch 29/40\n",
      "500/500 [==============================] - 344s - loss: 0.2602 - val_loss: 0.2765\n",
      "Epoch 30/40\n",
      "500/500 [==============================] - 344s - loss: 0.2596 - val_loss: 0.2795\n",
      "Epoch 31/40\n",
      "500/500 [==============================] - 344s - loss: 0.2598 - val_loss: 0.2688\n",
      "Epoch 32/40\n",
      "500/500 [==============================] - 344s - loss: 0.2590 - val_loss: 0.2724\n",
      "Epoch 33/40\n",
      "500/500 [==============================] - 344s - loss: 0.2581 - val_loss: 0.2754\n",
      "Epoch 34/40\n",
      "500/500 [==============================] - 344s - loss: 0.2570 - val_loss: 0.2688\n",
      "Epoch 35/40\n",
      "500/500 [==============================] - 344s - loss: 0.2559 - val_loss: 0.2753\n",
      "Epoch 36/40\n",
      "500/500 [==============================] - 345s - loss: 0.2552 - val_loss: 0.2719\n",
      "Epoch 37/40\n",
      "500/500 [==============================] - 344s - loss: 0.2552 - val_loss: 0.2745\n",
      "Epoch 38/40\n",
      "500/500 [==============================] - 344s - loss: 0.2537 - val_loss: 0.2761\n",
      "Epoch 39/40\n",
      "500/500 [==============================] - 344s - loss: 0.2546 - val_loss: 0.2793\n",
      "Epoch 40/40\n",
      "500/500 [==============================] - 345s - loss: 0.2532 - val_loss: 0.2782\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.GRU(32,\n",
    "                     dropout=0.1,\n",
    "                     recurrent_dropout=0.5,\n",
    "                     return_sequences=True,\n",
    "                     input_shape=(None, float_data.shape[-1])))\n",
    "model.add(layers.GRU(64, activation='relu',\n",
    "                     dropout=0.1, \n",
    "                     recurrent_dropout=0.5))\n",
    "model.add(layers.Dense(1))\n",
    "\n",
    "model.compile(optimizer=RMSprop(), loss='mae')\n",
    "history = model.fit_generator(train_gen,\n",
    "                              steps_per_epoch=500,\n",
    "                              epochs=40,\n",
    "                              validation_data=val_gen,\n",
    "                              validation_steps=val_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at our results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f33151ee630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3315184390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(loss))\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the added layers does improve ours results by a bit, albeit not very significantly. We can draw two conclusions:\n",
    "\n",
    "* Since we are still not overfitting too badly, we could safely increase the size of our layers, in quest for a bit of validation loss \n",
    "improvement. This does have a non-negligible computational cost, though. \n",
    "* Since adding a layer did not help us by a significant factor, we may be seeing diminishing returns to increasing network capacity at this \n",
    "point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using bidirectional RNNs\n",
    "\n",
    "\n",
    "The last technique that we will introduce in this section is called \"bidirectional RNNs\". A bidirectional RNN is common RNN variant which \n",
    "can offer higher performance than a regular RNN on certain tasks. It is frequently used in natural language processing -- you could call it \n",
    "the Swiss army knife of deep learning for NLP.\n",
    "\n",
    "RNNs are notably order-dependent, or time-dependent: they process the timesteps of their input sequences in order, and shuffling or \n",
    "reversing the timesteps can completely change the representations that the RNN will extract from the sequence. This is precisely the reason \n",
    "why they perform well on problems where order is meaningful, such as our temperature forecasting problem. A bidirectional RNN exploits \n",
    "the order-sensitivity of RNNs: it simply consists of two regular RNNs, such as the GRU or LSTM layers that you are already familiar with, \n",
    "each processing input sequence in one direction (chronologically and antichronologically), then merging their representations. By \n",
    "processing a sequence both way, a bidirectional RNN is able to catch patterns that may have been overlooked by a one-direction RNN.\n",
    "\n",
    "Remarkably, the fact that the RNN layers in this section have so far processed sequences in chronological order (older timesteps first) may \n",
    "have been an arbitrary decision. At least, it's a decision we made no attempt at questioning so far. Could it be that our RNNs could have \n",
    "performed well enough if it were processing input sequences in antichronological order, for instance (newer timesteps first)? Let's try \n",
    "this in practice and see what we get. All we need to do is write a variant of our data generator, where the input sequences get reverted \n",
    "along the time dimension (replace the last line with `yield samples[:, ::-1, :], targets`). Training the same one-GRU-layer network as we \n",
    "used in the first experiment in this section, we get the following results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reverse_order_generator(data, lookback, delay, min_index, max_index,\n",
    "                            shuffle=False, batch_size=128, step=6):\n",
    "    if max_index is None:\n",
    "        max_index = len(data) - delay - 1\n",
    "    i = min_index + lookback\n",
    "    while 1:\n",
    "        if shuffle:\n",
    "            rows = np.random.randint(\n",
    "                min_index + lookback, max_index, size=batch_size)\n",
    "        else:\n",
    "            if i + batch_size >= max_index:\n",
    "                i = min_index + lookback\n",
    "            rows = np.arange(i, min(i + batch_size, max_index))\n",
    "            i += len(rows)\n",
    "\n",
    "        samples = np.zeros((len(rows),\n",
    "                           lookback // step,\n",
    "                           data.shape[-1]))\n",
    "        targets = np.zeros((len(rows),))\n",
    "        for j, row in enumerate(rows):\n",
    "            indices = range(rows[j] - lookback, rows[j], step)\n",
    "            samples[j] = data[indices]\n",
    "            targets[j] = data[rows[j] + delay][1]\n",
    "        yield samples[:, ::-1, :], targets\n",
    "        \n",
    "train_gen_reverse = reverse_order_generator(\n",
    "    float_data,\n",
    "    lookback=lookback,\n",
    "    delay=delay,\n",
    "    min_index=0,\n",
    "    max_index=200000,\n",
    "    shuffle=True,\n",
    "    step=step, \n",
    "    batch_size=batch_size)\n",
    "val_gen_reverse = reverse_order_generator(\n",
    "    float_data,\n",
    "    lookback=lookback,\n",
    "    delay=delay,\n",
    "    min_index=200001,\n",
    "    max_index=300000,\n",
    "    step=step,\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "500/500 [==============================] - 172s - loss: 0.4781 - val_loss: 0.4797\n",
      "Epoch 2/20\n",
      "500/500 [==============================] - 171s - loss: 0.4529 - val_loss: 0.4679\n",
      "Epoch 3/20\n",
      "500/500 [==============================] - 170s - loss: 0.4071 - val_loss: 0.4536\n",
      "Epoch 4/20\n",
      "500/500 [==============================] - 171s - loss: 0.3670 - val_loss: 0.4398\n",
      "Epoch 5/20\n",
      "500/500 [==============================] - 170s - loss: 0.3343 - val_loss: 0.4320\n",
      "Epoch 6/20\n",
      "500/500 [==============================] - 170s - loss: 0.3191 - val_loss: 0.4388\n",
      "Epoch 7/20\n",
      "500/500 [==============================] - 170s - loss: 0.3065 - val_loss: 0.4186\n",
      "Epoch 8/20\n",
      "500/500 [==============================] - 170s - loss: 0.2938 - val_loss: 0.4014\n",
      "Epoch 9/20\n",
      "500/500 [==============================] - 170s - loss: 0.2824 - val_loss: 0.4077\n",
      "Epoch 10/20\n",
      "500/500 [==============================] - 170s - loss: 0.2724 - val_loss: 0.4090\n",
      "Epoch 11/20\n",
      "500/500 [==============================] - 170s - loss: 0.2670 - val_loss: 0.3990\n",
      "Epoch 12/20\n",
      "500/500 [==============================] - 170s - loss: 0.2613 - val_loss: 0.4146\n",
      "Epoch 13/20\n",
      "500/500 [==============================] - 170s - loss: 0.2548 - val_loss: 0.4013\n",
      "Epoch 14/20\n",
      "500/500 [==============================] - 170s - loss: 0.2521 - val_loss: 0.4086\n",
      "Epoch 15/20\n",
      "500/500 [==============================] - 170s - loss: 0.2458 - val_loss: 0.4178\n",
      "Epoch 16/20\n",
      "500/500 [==============================] - 170s - loss: 0.2437 - val_loss: 0.4097\n",
      "Epoch 17/20\n",
      "500/500 [==============================] - 170s - loss: 0.2416 - val_loss: 0.4163\n",
      "Epoch 18/20\n",
      "500/500 [==============================] - 170s - loss: 0.2373 - val_loss: 0.4174\n",
      "Epoch 19/20\n",
      "500/500 [==============================] - 170s - loss: 0.2355 - val_loss: 0.4064\n",
      "Epoch 20/20\n",
      "500/500 [==============================] - 170s - loss: 0.2313 - val_loss: 0.4261\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(layers.GRU(32, input_shape=(None, float_data.shape[-1])))\n",
    "model.add(layers.Dense(1))\n",
    "\n",
    "model.compile(optimizer=RMSprop(), loss='mae')\n",
    "history = model.fit_generator(train_gen_reverse,\n",
    "                              steps_per_epoch=500,\n",
    "                              epochs=20,\n",
    "                              validation_data=val_gen_reverse,\n",
    "                              validation_steps=val_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3314e81860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlPRFRDKIkr6ISAb5f90CkpLZvdpGAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f330f25bcc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(loss))\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "So the reversed-order GRU strongly underperforms even the common-sense baseline, indicating that the in our case chronological processing is very \n",
    "important to the success of our approach. This makes perfect sense: the underlying GRU layer will typically be better at remembering the \n",
    "recent past than the distant past, and naturally the more recent weather data points are more predictive than older data points in our \n",
    "problem (that's precisely what makes the common-sense baseline a fairly strong baseline). Thus the chronological version of the layer is \n",
    "bound to outperform the reversed-order version. Importantly, this is generally not true for many other problems, including natural \n",
    "language: intuitively, the importance of a word in understanding a sentence is not usually dependent on its position in the sentence. Let's \n",
    "try the same trick on the LSTM IMDB example from the previous section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 111s - loss: 0.4965 - acc: 0.7648 - val_loss: 0.3593 - val_acc: 0.8570\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 107s - loss: 0.3105 - acc: 0.8810 - val_loss: 0.3329 - val_acc: 0.8648\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 105s - loss: 0.2566 - acc: 0.9057 - val_loss: 0.3863 - val_acc: 0.8770\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 106s - loss: 0.2231 - acc: 0.9195 - val_loss: 0.3471 - val_acc: 0.8556\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 105s - loss: 0.1912 - acc: 0.9314 - val_loss: 0.3346 - val_acc: 0.8694\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 105s - loss: 0.1721 - acc: 0.9379 - val_loss: 0.3621 - val_acc: 0.8520\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 105s - loss: 0.1613 - acc: 0.9427 - val_loss: 0.3438 - val_acc: 0.8694\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 105s - loss: 0.1502 - acc: 0.9503 - val_loss: 0.3890 - val_acc: 0.8588\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 105s - loss: 0.1369 - acc: 0.9520 - val_loss: 0.3626 - val_acc: 0.8768\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 105s - loss: 0.1249 - acc: 0.9579 - val_loss: 0.4639 - val_acc: 0.8566\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "\n",
    "# Number of words to consider as features\n",
    "max_features = 10000\n",
    "# Cut texts after this number of words (among top max_features most common words)\n",
    "maxlen = 500\n",
    "\n",
    "# Load data\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "\n",
    "# Reverse sequences\n",
    "x_train = [x[::-1] for x in x_train]\n",
    "x_test = [x[::-1] for x in x_test]\n",
    "\n",
    "# Pad sequences\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(max_features, 128))\n",
    "model.add(layers.LSTM(32))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=128,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We get near-identical performance as the chronological-order LSTM we tried in the previous section.\n",
    "\n",
    "Thus, remarkably, on such a text dataset, reversed-order processing works just as well as chronological processing, confirming our \n",
    "hypothesis that, albeit word order *does* matter in understanding language, *which* order you use isn't crucial. Importantly, a RNN trained \n",
    "on reversed sequences will learn different representations than one trained on the original sequences, in much the same way that you would \n",
    "have quite different mental models if time flowed backwards in the real world -- if you lived a life where you died on your first day and \n",
    "you were born on your last day. In machine learning, representations that are *different* yet *useful* are always worth exploiting, and the \n",
    "more they differ the better: they offer a new angle from which to look at your data, capturing aspects of the data that were missed by other \n",
    "approaches, and thus they can allow to boost performance on a task. This is the intuition behind \"ensembling\", a concept that we will \n",
    "introduce in the next chapter.\n",
    "\n",
    "A bidirectional RNN exploits this idea to improve upon the performance of chronological-order RNNs: it looks at its inputs sequence both \n",
    "ways, obtaining potentially richer representations and capturing patterns that may have been missed by the chronological-order version alone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![bidirectional rnn](https://s3.amazonaws.com/book.keras.io/img/ch6/bidirectional_rnn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To instantiate a bidirectional RNN in Keras, one would use the `Bidirectional` layer, which takes as first argument a recurrent layer \n",
    "instance. `Bidirectional` will create a second, separate instance of this recurrent layer, and will use one instance for processing the \n",
    "input sequences in chronological order and the other instance for processing the input sequences in reversed order. Let's try it on the \n",
    "IMDB sentiment analysis task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 214s - loss: 0.5994 - acc: 0.6865 - val_loss: 0.4722 - val_acc: 0.8090\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 213s - loss: 0.3673 - acc: 0.8543 - val_loss: 0.3769 - val_acc: 0.8448\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 213s - loss: 0.2743 - acc: 0.8972 - val_loss: 0.3196 - val_acc: 0.8688\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 211s - loss: 0.2310 - acc: 0.9150 - val_loss: 0.2972 - val_acc: 0.8856\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 211s - loss: 0.2009 - acc: 0.9261 - val_loss: 0.4461 - val_acc: 0.8514\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 210s - loss: 0.1912 - acc: 0.9339 - val_loss: 0.3636 - val_acc: 0.8640\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 209s - loss: 0.1670 - acc: 0.9423 - val_loss: 0.3476 - val_acc: 0.8580\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 210s - loss: 0.1523 - acc: 0.9469 - val_loss: 0.3887 - val_acc: 0.8830\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 209s - loss: 0.1431 - acc: 0.9506 - val_loss: 0.3781 - val_acc: 0.8810\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 209s - loss: 0.1366 - acc: 0.9521 - val_loss: 0.3713 - val_acc: 0.8792\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(layers.Embedding(max_features, 32))\n",
    "model.add(layers.Bidirectional(layers.LSTM(32)))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = model.fit(x_train, y_train, epochs=10, batch_size=128, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It performs slightly better than the regular LSTM we tried in the previous section, going above 88% validation accuracy. It also seems to \n",
    "overfit faster, which is unsurprising since a bidirectional layer has twice more parameters than a chronological LSTM. With some \n",
    "regularization, the bidirectional approach would likely be a strong performer on this task.\n",
    "\n",
    "Now let's try the same approach on the weather prediction task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "500/500 [==============================] - 325s - loss: 0.3029 - val_loss: 0.2660\n",
      "Epoch 2/40\n",
      "500/500 [==============================] - 324s - loss: 0.2751 - val_loss: 0.2660\n",
      "Epoch 3/40\n",
      "500/500 [==============================] - 326s - loss: 0.2668 - val_loss: 0.2628\n",
      "Epoch 4/40\n",
      "500/500 [==============================] - 326s - loss: 0.2594 - val_loss: 0.2615\n",
      "Epoch 5/40\n",
      "500/500 [==============================] - 324s - loss: 0.2532 - val_loss: 0.2684\n",
      "Epoch 6/40\n",
      "500/500 [==============================] - 324s - loss: 0.2442 - val_loss: 0.2674\n",
      "Epoch 7/40\n",
      "500/500 [==============================] - 324s - loss: 0.2405 - val_loss: 0.2700\n",
      "Epoch 8/40\n",
      "500/500 [==============================] - 324s - loss: 0.2343 - val_loss: 0.2782\n",
      "Epoch 9/40\n",
      "500/500 [==============================] - 324s - loss: 0.2293 - val_loss: 0.2778\n",
      "Epoch 10/40\n",
      "500/500 [==============================] - 324s - loss: 0.2233 - val_loss: 0.2813\n",
      "Epoch 11/40\n",
      "500/500 [==============================] - 324s - loss: 0.2167 - val_loss: 0.2978\n",
      "Epoch 12/40\n",
      "500/500 [==============================] - 324s - loss: 0.2116 - val_loss: 0.2984\n",
      "Epoch 13/40\n",
      "500/500 [==============================] - 324s - loss: 0.2061 - val_loss: 0.2920\n",
      "Epoch 14/40\n",
      "500/500 [==============================] - 323s - loss: 0.2008 - val_loss: 0.3016\n",
      "Epoch 15/40\n",
      "500/500 [==============================] - 324s - loss: 0.1952 - val_loss: 0.2985\n",
      "Epoch 16/40\n",
      "500/500 [==============================] - 324s - loss: 0.1915 - val_loss: 0.3029\n",
      "Epoch 17/40\n",
      "500/500 [==============================] - 323s - loss: 0.1862 - val_loss: 0.3127\n",
      "Epoch 18/40\n",
      "500/500 [==============================] - 324s - loss: 0.1821 - val_loss: 0.3079\n",
      "Epoch 19/40\n",
      "500/500 [==============================] - 324s - loss: 0.1772 - val_loss: 0.3116\n",
      "Epoch 20/40\n",
      "500/500 [==============================] - 323s - loss: 0.1735 - val_loss: 0.3151\n",
      "Epoch 21/40\n",
      "500/500 [==============================] - 323s - loss: 0.1705 - val_loss: 0.3208\n",
      "Epoch 22/40\n",
      "500/500 [==============================] - 324s - loss: 0.1664 - val_loss: 0.3345\n",
      "Epoch 23/40\n",
      "500/500 [==============================] - 323s - loss: 0.1631 - val_loss: 0.3162\n",
      "Epoch 24/40\n",
      "500/500 [==============================] - 324s - loss: 0.1604 - val_loss: 0.3141\n",
      "Epoch 25/40\n",
      "500/500 [==============================] - 324s - loss: 0.1572 - val_loss: 0.3173\n",
      "Epoch 26/40\n",
      "500/500 [==============================] - 325s - loss: 0.1559 - val_loss: 0.3156\n",
      "Epoch 27/40\n",
      "500/500 [==============================] - 324s - loss: 0.1530 - val_loss: 0.3227\n",
      "Epoch 28/40\n",
      "500/500 [==============================] - 324s - loss: 0.1521 - val_loss: 0.3288\n",
      "Epoch 29/40\n",
      "500/500 [==============================] - 325s - loss: 0.1496 - val_loss: 0.3264\n",
      "Epoch 30/40\n",
      "500/500 [==============================] - 324s - loss: 0.1481 - val_loss: 0.3266\n",
      "Epoch 31/40\n",
      "500/500 [==============================] - 323s - loss: 0.1456 - val_loss: 0.3241\n",
      "Epoch 32/40\n",
      "500/500 [==============================] - 323s - loss: 0.1436 - val_loss: 0.3293\n",
      "Epoch 33/40\n",
      "500/500 [==============================] - 324s - loss: 0.1426 - val_loss: 0.3301\n",
      "Epoch 34/40\n",
      "500/500 [==============================] - 324s - loss: 0.1409 - val_loss: 0.3298\n",
      "Epoch 35/40\n",
      "500/500 [==============================] - 324s - loss: 0.1399 - val_loss: 0.3372\n",
      "Epoch 36/40\n",
      "500/500 [==============================] - 323s - loss: 0.1387 - val_loss: 0.3304\n",
      "Epoch 37/40\n",
      "500/500 [==============================] - 324s - loss: 0.1388 - val_loss: 0.3324\n",
      "Epoch 38/40\n",
      "500/500 [==============================] - 324s - loss: 0.1362 - val_loss: 0.3317\n",
      "Epoch 39/40\n",
      "500/500 [==============================] - 323s - loss: 0.1342 - val_loss: 0.3319\n",
      "Epoch 40/40\n",
      "500/500 [==============================] - 324s - loss: 0.1350 - val_loss: 0.3289\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Bidirectional(\n",
    "    layers.GRU(32), input_shape=(None, float_data.shape[-1])))\n",
    "model.add(layers.Dense(1))\n",
    "\n",
    "model.compile(optimizer=RMSprop(), loss='mae')\n",
    "history = model.fit_generator(train_gen,\n",
    "                              steps_per_epoch=500,\n",
    "                              epochs=40,\n",
    "                              validation_data=val_gen,\n",
    "                              validation_steps=val_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "It performs about as well as the regular GRU layer. It's easy to understand why: all of the predictive capacity must be coming from the \n",
    "chronological half of the network, since the anti-chronological half is known to be severely underperforming on this task (again, because \n",
    "the recent past matters much more than the distant past in this case)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Going even further\n",
    "\n",
    "At this stage, there are still many other things you could try in order to improve performance on our weather forecasting problem:\n",
    "\n",
    "* Adjust the number of units in each recurrent layer in the stacked setup. Our current choices are largely arbitrary and thus likely \n",
    "suboptimal.\n",
    "* Adjust the learning rate used by our `RMSprop` optimizer.\n",
    "* Try using `LSTM` layers instead of `GRU` layers.\n",
    "* Try using a bigger densely-connected regressor on top of the recurrent layers, i.e. a bigger `Dense` layer or even a stack of `Dense` \n",
    "layers.\n",
    "* Don't forget to eventually run the best performing models (in terms of validation MAE) on the test set! Least you start developing \n",
    "architectures that are overfitting to the validation set.   \n",
    "\n",
    "As usual: deep learning is more an art than a science, and while we can provide guidelines as to what is likely to work or not work on a \n",
    "given problem, ultimately every problem is unique and you will have to try and evaluate different strategies empirically. There is \n",
    "currently no theory that will tell you in advance precisely what you should do to optimally solve a problem. You must try and iterate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence processing with convnets\n",
    "## Implementing a 1D convnet\n",
    "\n",
    "In Keras, you would use a 1D convnet via the `Conv1D` layer, which has a very similar interface to `Conv2D`. It takes as input 3D tensors \n",
    "with shape `(samples, time, features)` and also returns similarly-shaped 3D tensors. The convolution window is a 1D window on the temporal \n",
    "axis, axis 1 in the input tensor.\n",
    "\n",
    "Let's build a simple 2-layer 1D convnet and apply it to the IMDB sentiment classification task that you are already familiar with.\n",
    "\n",
    "As a reminder, this is the code for obtaining and preprocessing the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "25000 train sequences\n",
      "25000 test sequences\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (25000, 500)\n",
      "x_test shape: (25000, 500)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "max_features = 10000  # number of words to consider as features\n",
    "max_len = 500  # cut texts after this number of words (among top max_features most common words)\n",
    "\n",
    "print('Loading data...')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=max_len)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=max_len)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1D convnets are structured in the same way as their 2D counter-parts that you have used in Chapter 5: they consist of a stack of `Conv1D` \n",
    "and `MaxPooling1D` layers, eventually ending in either a global pooling layer or a `Flatten` layer, turning the 3D outputs into 2D outputs, \n",
    "allowing to add one or more `Dense` layers to the model, for classification or regression.\n",
    "\n",
    "One difference, though, is the fact that we can afford to use larger convolution windows with 1D convnets. Indeed, with a 2D convolution \n",
    "layer, a 3x3 convolution window contains 3*3 = 9 feature vectors, but with a 1D convolution layer, a convolution window of size 3 would \n",
    "only contain 3 feature vectors. We can thus easily afford 1D convolution windows of size 7 or 9.\n",
    "\n",
    "This is our example 1D convnet for the IMDB dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/heathermattie/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 500, 128)          1280000   \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 494, 32)           28704     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 98, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 92, 32)            7200      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,315,937\n",
      "Trainable params: 1,315,937\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /Users/heathermattie/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /Users/heathermattie/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 87s 4ms/step - loss: 0.8337 - acc: 0.5088 - val_loss: 0.6875 - val_acc: 0.5642\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 84s 4ms/step - loss: 0.6700 - acc: 0.6401 - val_loss: 0.6642 - val_acc: 0.6580\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 87s 4ms/step - loss: 0.6234 - acc: 0.7555 - val_loss: 0.6075 - val_acc: 0.7434\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 81s 4ms/step - loss: 0.5252 - acc: 0.8101 - val_loss: 0.4846 - val_acc: 0.8078\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 81s 4ms/step - loss: 0.4110 - acc: 0.8477 - val_loss: 0.4288 - val_acc: 0.8312\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 77s 4ms/step - loss: 0.3495 - acc: 0.8647 - val_loss: 0.4199 - val_acc: 0.8378\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 78s 4ms/step - loss: 0.3083 - acc: 0.8645 - val_loss: 0.4390 - val_acc: 0.8200\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 75s 4ms/step - loss: 0.2744 - acc: 0.8550 - val_loss: 0.4152 - val_acc: 0.8132\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 75s 4ms/step - loss: 0.2516 - acc: 0.8312 - val_loss: 0.4415 - val_acc: 0.7874\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 75s 4ms/step - loss: 0.2251 - acc: 0.8131 - val_loss: 0.5002 - val_acc: 0.7500\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(max_features, 128, input_length=max_len))\n",
    "model.add(layers.Conv1D(32, 7, activation='relu'))\n",
    "model.add(layers.MaxPooling1D(5))\n",
    "model.add(layers.Conv1D(32, 7, activation='relu'))\n",
    "model.add(layers.GlobalMaxPooling1D())\n",
    "model.add(layers.Dense(1))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=RMSprop(lr=1e-4),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=128,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are our training and validation results: validation accuracy is somewhat lower than that of the LSTM we used two sections ago, but \n",
    "runtime is faster, both on CPU and GPU (albeit the exact speedup will vary greatly depending on your exact configuration). At that point, \n",
    "we could re-train this model for the right number of epochs (8), and run it on the test set. This is a convincing demonstration that a 1D \n",
    "convnet can offer a fast, cheap alternative to a recurrent network on a word-level sentiment classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining CNNs and RNNs to process long sequences\n",
    "\n",
    "\n",
    "Because 1D convnets process input patches independently, they are not sensitive to the order of the timesteps (beyond a local scale, the \n",
    "size of the convolution windows), unlike RNNs. Of course, in order to be able to recognize longer-term patterns, one could stack many \n",
    "convolution layers and pooling layers, resulting in upper layers that would \"see\" long chunks of the original inputs -- but that's still a \n",
    "fairly weak way to induce order-sensitivity. One way to evidence this weakness is to try 1D convnets on the temperature forecasting problem \n",
    "from the previous section, where order-sensitivity was key to produce good predictions. Let's see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We reuse the following variables defined in the last section:\n",
    "# float_data, train_gen, val_gen, val_steps\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "data_dir = '/home/ubuntu/data/'\n",
    "fname = os.path.join(data_dir, 'jena_climate_2009_2016.csv')\n",
    "\n",
    "f = open(fname)\n",
    "data = f.read()\n",
    "f.close()\n",
    "\n",
    "lines = data.split('\\n')\n",
    "header = lines[0].split(',')\n",
    "lines = lines[1:]\n",
    "\n",
    "float_data = np.zeros((len(lines), len(header) - 1))\n",
    "for i, line in enumerate(lines):\n",
    "    values = [float(x) for x in line.split(',')[1:]]\n",
    "    float_data[i, :] = values\n",
    "    \n",
    "mean = float_data[:200000].mean(axis=0)\n",
    "float_data -= mean\n",
    "std = float_data[:200000].std(axis=0)\n",
    "float_data /= std\n",
    "\n",
    "def generator(data, lookback, delay, min_index, max_index,\n",
    "              shuffle=False, batch_size=128, step=6):\n",
    "    if max_index is None:\n",
    "        max_index = len(data) - delay - 1\n",
    "    i = min_index + lookback\n",
    "    while 1:\n",
    "        if shuffle:\n",
    "            rows = np.random.randint(\n",
    "                min_index + lookback, max_index, size=batch_size)\n",
    "        else:\n",
    "            if i + batch_size >= max_index:\n",
    "                i = min_index + lookback\n",
    "            rows = np.arange(i, min(i + batch_size, max_index))\n",
    "            i += len(rows)\n",
    "\n",
    "        samples = np.zeros((len(rows),\n",
    "                           lookback // step,\n",
    "                           data.shape[-1]))\n",
    "        targets = np.zeros((len(rows),))\n",
    "        for j, row in enumerate(rows):\n",
    "            indices = range(rows[j] - lookback, rows[j], step)\n",
    "            samples[j] = data[indices]\n",
    "            targets[j] = data[rows[j] + delay][1]\n",
    "        yield samples, targets\n",
    "        \n",
    "lookback = 1440\n",
    "step = 6\n",
    "delay = 144\n",
    "batch_size = 128\n",
    "\n",
    "train_gen = generator(float_data,\n",
    "                      lookback=lookback,\n",
    "                      delay=delay,\n",
    "                      min_index=0,\n",
    "                      max_index=200000,\n",
    "                      shuffle=True,\n",
    "                      step=step, \n",
    "                      batch_size=batch_size)\n",
    "val_gen = generator(float_data,\n",
    "                    lookback=lookback,\n",
    "                    delay=delay,\n",
    "                    min_index=200001,\n",
    "                    max_index=300000,\n",
    "                    step=step,\n",
    "                    batch_size=batch_size)\n",
    "test_gen = generator(float_data,\n",
    "                     lookback=lookback,\n",
    "                     delay=delay,\n",
    "                     min_index=300001,\n",
    "                     max_index=None,\n",
    "                     step=step,\n",
    "                     batch_size=batch_size)\n",
    "\n",
    "# This is how many steps to draw from `val_gen`\n",
    "# in order to see the whole validation set:\n",
    "val_steps = (300000 - 200001 - lookback) // batch_size\n",
    "\n",
    "# This is how many steps to draw from `test_gen`\n",
    "# in order to see the whole test set:\n",
    "test_steps = (len(float_data) - 300001 - lookback) // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Conv1D(32, 5, activation='relu',\n",
    "                        input_shape=(None, float_data.shape[-1])))\n",
    "model.add(layers.MaxPooling1D(3))\n",
    "model.add(layers.Conv1D(32, 5, activation='relu'))\n",
    "model.add(layers.MaxPooling1D(3))\n",
    "model.add(layers.Conv1D(32, 5, activation='relu'))\n",
    "model.add(layers.GlobalMaxPooling1D())\n",
    "model.add(layers.Dense(1))\n",
    "\n",
    "model.compile(optimizer=RMSprop(), loss='mae')\n",
    "history = model.fit_generator(train_gen,\n",
    "                              steps_per_epoch=500,\n",
    "                              epochs=20,\n",
    "                              validation_data=val_gen,\n",
    "                              validation_steps=val_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(loss))\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The validation MAE stays in the low 0.40s: we cannot even beat our common-sense baseline using the small convnet. Again, this is because \n",
    "our convnet looks for patterns anywhere in the input timeseries, and has no knowledge of the temporal position of a pattern it sees (e.g. \n",
    "towards the beginning, towards the end, etc.). Since more recent datapoints should be interpreted differently from older datapoints in the \n",
    "case of this specific forecasting problem, the convnet fails at producing meaningful results here. This limitation of convnets was not an \n",
    "issue on IMDB, because patterns of keywords that are associated with a positive or a negative sentiment will be informative independently \n",
    "of where they are found in the input sentences.\n",
    "\n",
    "One strategy to combine the speed and lightness of convnets with the order-sensitivity of RNNs is to use a 1D convnet as a preprocessing \n",
    "step before a RNN. This is especially beneficial when dealing with sequences that are so long that they couldn't realistically be processed \n",
    "with RNNs, e.g. sequences with thousands of steps. The convnet will turn the long input sequence into much shorter (downsampled) sequences \n",
    "of higher-level features. This sequence of extracted features then becomes the input to the RNN part of the network.\n",
    "\n",
    "\n",
    "This technique is not seen very often in research papers and practical applications, possibly because it is not very well known. It is very \n",
    "effective and ought to be more common. Let's try this out on the temperature forecasting dataset. Because this strategy allows us to \n",
    "manipulate much longer sequences, we could either look at data from further back (by increasing the `lookback` parameter of the data \n",
    "generator), or look at high-resolution timeseries (by decreasing the `step` parameter of the generator). Here, we will chose (somewhat \n",
    "arbitrarily) to use a `step` twice smaller, resulting in twice longer timeseries, where the weather data is being sampled at a rate of one \n",
    "point per 30 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This was previously set to 6 (one point per hour).\n",
    "# Now 3 (one point per 30 min).\n",
    "step = 3\n",
    "lookback = 720  # Unchanged\n",
    "delay = 144 # Unchanged\n",
    "\n",
    "train_gen = generator(float_data,\n",
    "                      lookback=lookback,\n",
    "                      delay=delay,\n",
    "                      min_index=0,\n",
    "                      max_index=200000,\n",
    "                      shuffle=True,\n",
    "                      step=step)\n",
    "val_gen = generator(float_data,\n",
    "                    lookback=lookback,\n",
    "                    delay=delay,\n",
    "                    min_index=200001,\n",
    "                    max_index=300000,\n",
    "                    step=step)\n",
    "test_gen = generator(float_data,\n",
    "                     lookback=lookback,\n",
    "                     delay=delay,\n",
    "                     min_index=300001,\n",
    "                     max_index=None,\n",
    "                     step=step)\n",
    "val_steps = (300000 - 200001 - lookback) // 128\n",
    "test_steps = (len(float_data) - 300001 - lookback) // 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is our model, starting with two `Conv1D` layers and following-up with a `GRU` layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layers.Conv1D(32, 5, activation='relu',\n",
    "                        input_shape=(None, float_data.shape[-1])))\n",
    "model.add(layers.MaxPooling1D(3))\n",
    "model.add(layers.Conv1D(32, 5, activation='relu'))\n",
    "model.add(layers.GRU(32, dropout=0.1, recurrent_dropout=0.5))\n",
    "model.add(layers.Dense(1))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=RMSprop(), loss='mae')\n",
    "history = model.fit_generator(train_gen,\n",
    "                              steps_per_epoch=500,\n",
    "                              epochs=20,\n",
    "                              validation_data=val_gen,\n",
    "                              validation_steps=val_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(loss))\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Judging from the validation loss, this setup is not quite as good as the regularized GRU alone, but it's significantly faster. It is \n",
    "looking at twice more data, which in this case doesn't appear to be hugely helpful, but may be important for other datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapping up\n",
    "\n",
    "Here's what you should take away from this section:\n",
    "\n",
    "* In the same way that 2D convnets perform well for processing visual patterns in 2D space, 1D convnets perform well for processing \n",
    "temporal patterns. They offer a faster alternative to RNNs on some problems, in particular NLP tasks.\n",
    "* Typically 1D convnets are structured much like their 2D equivalents from the world of computer vision: they consist of stacks of `Conv1D` \n",
    "layers and `MaxPooling1D` layers, eventually ending in a global pooling operation or flattening operation.\n",
    "* Because RNNs are extremely expensive for processing very long sequences, but 1D convnets are cheap, it can be a good idea to use a 1D \n",
    "convnet as a preprocessing step before a RNN, shortening the sequence and extracting useful representations for the RNN to process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
