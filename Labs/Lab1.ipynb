{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab #1\n",
    "\n",
    "TA: Matt Ploenzke\n",
    "Date: 4/5/2019\n",
    "\n",
    "Today's lab consists of practice questions to review the topics presented thus far in class. We will be focusing on:\n",
    "    1. Neural network terminology and architecture\n",
    "    2. python\n",
    "    3. Forward and backward propagation\n",
    "    4. Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "Let's review the terminology introduced by thinking about how to design a model for each the following scenarios. It's important to remember that while there is more than one correct answer in these cases, we want to develop an intuition to help save time in parameter tuning, training, computational resources, etc. We'll also briefy touch on some advanced topics to provide a foundation for later in the course, and remember you do not need to use a deep neural network in every case.\n",
    "\n",
    "*Case 1:* The input is the MNIST handwritten digits dataset (features are 28x28 pixel intensities and labels are digits 0-9). We want to predict which digit the image represents and there are only 10 images per category ($N=100$).\n",
    "\n",
    "    - \n",
    "\n",
    "*Case 2:* The identical setup but this time there are thousands of images per category.\n",
    "\n",
    "    - \n",
    "\n",
    "*Case 3:* The identical setup as case 2 but this time images may contain multiple digits or no digits at all.\n",
    "\n",
    "    - \n",
    "\n",
    "*Case 4:*  The covariates are BMI measurements and reported smoking status, the labels are binary denoting cardiovascular disease. Our sample consists of 70 individuals and we want to predict an individuals' health status based on their BMI and smoking status. We are interested in the effect of BMI on cardiovascular disease.\n",
    "\n",
    "    - \n",
    "\n",
    "*Case 5:* The input consists of thousands of images of different animals and we want to classify which animal the image contains. \n",
    "\n",
    "    - \n",
    "\n",
    "*Case 6:* The input consists of thousands of English sentences and we want to predict the next word in the sentences. \n",
    "\n",
    "    - \n",
    "\n",
    "*Case 7:* The input consists of biomarker status for thousands of loci across thousands of individuals (i.e. Ancestry.com). There are no associated labels and we wish to learn about population substructure. \n",
    "\n",
    "    - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "a) Start a jupyter notebook and/or create a python file\n",
    "\n",
    "b) Install and load numpy. What is your package manager?\n",
    "\n",
    "c) If you don't have keras and tensorflow installed, install those now. \n",
    "\n",
    "d) Ask Matt any questions about python now or forever hold your peace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "Draw the architecture of a neural network satisying the following conditions:\n",
    "    1. X is a univariate covariate. We will consider the case when X=5.\n",
    "    2. There are two hidden layers. The first consists of two nodes, each with a bias term taking values (-1 and 1, respectively). The weight going to the first node takes value 0.5 and the weight going to the second node takes value -0.5.\n",
    "    3. The nodes in hidden layer 1 each use a linear activation function.\n",
    "    4. Hidden layer 2 consists of a single node with no bias term and the ReLU activation function. The weight from node 1 in hidden layer 1 is 0.3 and the weight from node 2 in hidden layer 1 is 0.7.\n",
    "    5. Hidden layer 2 outputs to a single output node. The bias term for the output node is 0.5 and the weight from hidden layer 2 is 2. \n",
    "    6. The loss function to be optimized is squared loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "Implement a single forward pass of the network described in Question 3. You do not need to implement the network in keras and should instead use numpy operations (either scalar or matrix). Start by defining the weights and input matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now perform the forward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's print the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The values for the hidden layer 1 are: [[ 1.5 -1.5]]\n",
      "The values for the hidden layer 2 are: [[-0.6]]\n",
      "The post-relu values for the hidden layer 2 are: [[0.]]\n",
      "The value for the output layer is: [[0.5]]\n"
     ]
    }
   ],
   "source": [
    "print('The values for the hidden layer 1 are:', hidden1)\n",
    "print('The values for the hidden layer 2 are:', hidden2)\n",
    "print('The post-relu values for the hidden layer 2 are:', hidden2_clamped)\n",
    "print('The value for the output layer is:', y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the loss for the training example given a label of Y=.25."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is: [[0.0625]]\n"
     ]
    }
   ],
   "source": [
    "y_i = .25 # positive outcome as defined in the problem\n",
    "print('The loss is:',loss_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a single backward pass of the network. Again use numpy. Start by defining the individual gradient terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that a maximum of two quantities are needed for each layer: \n",
    "    \n",
    "    1) \n",
    "    2) \n",
    "    \n",
    "What is the purpose of each of these quantities?\n",
    "\n",
    "    - \n",
    "    - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "Load the MNIST dataset provided by keras. This contains 60,000 28x28 grayscale images of the 10 digits, along with a test set of 10,000 images. Split the data into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "\n",
    "import keras\n",
    "from keras import models\n",
    "from keras import layers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the shape of the training and testing datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's reshape the data to fit the keras format. Don't worry too much about this chunk for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, 28, 28)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, 28, 28)\n",
    "    input_shape = (1, 28, 28)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "    input_shape = (28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now print the shape again to see what changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2 in Homework 1 asks you to train a neural network on the Boston housing data. This dataset contains features on very different scales (for example there are both binary features and real-valued features). While the MNIST features take on values between 0 and 1 and do not need to be normalized, we will go through the exercise of normalizing the values before training our network.\n",
    "\n",
    "Can you think of other algorithms in which normalization is necessary? Is it necessary in the case of neural networks? Why or why not? \n",
    "\n",
    "    - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize the data. Be sure to normalize the test set with the training set mean and standard deviation. Don't forget to convert the training and testing sets to float32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How will the code above need to be changed for Boston housing dataset? Why?\n",
    "\n",
    "    - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we define and fit our model let's one-hot encode the labels. Don't forget to do the same for the testing labels and note you will not need to do this step in the case of regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now fit a shallow convolutional neural network with a single dense layer. Include 32 convolutional filters of size 3x3 and use the relu activation function.\n",
    "\n",
    "After the convolutional layer, flatted the tensor to be fed into the dense layer.\n",
    "\n",
    "In the dense layer use enough output nodes to have one corresponding to each class label (10). What is the activation function you should use here?\n",
    "\n",
    "In the optimizer use the `Adadelta` optimization function, and choose an appropriate loss function and model performance measure. \n",
    "\n",
    "Run the network for 5 epochs and use a batch_size of 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report the test set accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
