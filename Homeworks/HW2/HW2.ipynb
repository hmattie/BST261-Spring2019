{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework #2: Convolutional Neural Networks\n",
    "Due Monday, April 29th by 11:59pm\n",
    "\n",
    "Name:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "(a) You have an input volume that is 15x15x8 and pad it using *p = 2*. What is the dimension of the resulting volume?\n",
    "\n",
    "Your answer: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) You have an input volume that is 32x32x16 and apply max pooling with a stride of 2 and a filter of size of 2x2. What is the output volume?\n",
    "\n",
    "Your answer:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) You have an input volume that is 63x63x16 and convolve it with 32 filters that are each 7x7, and a stride of 1. You want to use a \"same\" convolution. What is the padding *p*?\n",
    "\n",
    "Your answer:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) You have an input volume that is 63x63x16 and convolve it with 32 filters that are each 7x7, using a stride of 2 and no padding. What is the output volume?\n",
    "\n",
    "Your answer:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: Classification of Chest X-rays\n",
    "Chest X-ray exams are one of the most frequent and cost-effective medical imaging examinations available. However, clinical diagnosis of a chest X-ray can be challenging and sometimes more difficult than diagnosis via chest CT imaging. The lack of large publicly available datasets with annotations means it is still very difficult, if not impossible, to achieve clinically relevant computer-aided detection and diagnosis (CAD) in real world medical sites with chest X-rays. One major hurdle in creating large X-ray image datasets is the lack resources for labeling so many images. Prior to the release of this dataset, Openi was the largest publicly available source of chest X-ray images with 4,143 images available.\n",
    "\n",
    "This NIH Chest X-ray Dataset is comprised of 112,120 X-ray images with disease labels from 30,805 unique patients. To create these labels, the authors used Natural Language Processing to text-mine disease classifications from the associated radiological reports. The labels are expected to be >90% accurate and suitable for weakly-supervised learning. The original radiology reports are not publicly available but you can find more details on the labeling process in this Open Access paper: \"ChestX-ray8: Hospital-scale Chest X-ray Database and Benchmarks on Weakly-Supervised Classification and Localization of Common Thorax Diseases.\" (Wang et al.)\n",
    "\n",
    "Here we will use a subset of the data, rather than all 112,120 images. The images have been split into training, validation and test sets, each with folders containing the images for a particular diagnosis (class). The full data set contains images with single labels and multi-lables, with a total of 15 unique diagnoses. Our subsample contains only single label images with a total of 7 diagnoses: atelectasis, effusion, infiltration, mass, nodule, none (no finding), and pneumothorax. Your task is to classify the images correctly by building multiple CNNs and comparing their performance.\n",
    "\n",
    "Here are what a few of the X-rays look like:\n",
    "\n",
    "<img src=\"chest_xrays.jpg\" width=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "import keras\n",
    "keras.__version__\n",
    "import numpy as np\n",
    "import os, shutil\n",
    "#import cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data\n",
    "\n",
    "The data are available on Dropbox and can be accessed [here](https://www.dropbox.com/sh/k23tp1a0um8u2xv/AACDoV9K9BJdU5ObjBw0mmwSa?dl=0). Be sure to unzip the folders before running the code below.\n",
    "\n",
    "Load the data and print the number of training, validation and test set examples there are of each class. Be sure to change the directory path provided below to your own data path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/Users/heathermattie/Dropbox/Summer Teaching/Summer Project 2018/Multiple Classes Data' # change this path\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train_dir')\n",
    "validation_dir = os.path.join(base_dir, 'validation_dir')\n",
    "test_dir = os.path.join(base_dir, 'test_dir')\n",
    "\n",
    "# Training Data\n",
    "train_atelectasis  = os.path.join(train_dir, 'atelectasis')\n",
    "train_effusion     = os.path.join(train_dir, 'effusion')\n",
    "train_infiltration = os.path.join(train_dir, 'infiltration')\n",
    "train_mass         = os.path.join(train_dir, 'mass')\n",
    "train_nodule       = os.path.join(train_dir, 'nodule')\n",
    "train_none         = os.path.join(train_dir, 'none')\n",
    "train_pneumothorax = os.path.join(train_dir, 'pneumothorax')\n",
    "\n",
    "# Validation Data\n",
    "val_atelectasis  = os.path.join(validation_dir, 'atelectasis')\n",
    "val_effusion     = os.path.join(validation_dir, 'effusion')\n",
    "val_infiltration = os.path.join(validation_dir, 'infiltration')\n",
    "val_mass         = os.path.join(validation_dir, 'mass')\n",
    "val_nodule       = os.path.join(validation_dir, 'nodule')\n",
    "val_none         = os.path.join(validation_dir, 'none')\n",
    "val_pneumothorax = os.path.join(validation_dir, 'pneumothorax')\n",
    "\n",
    "# Test Data\n",
    "test_atelectasis  = os.path.join(test_dir, 'atelectasis')\n",
    "test_effusion     = os.path.join(test_dir, 'effusion')\n",
    "test_infiltration = os.path.join(test_dir, 'infiltration')\n",
    "test_mass         = os.path.join(test_dir, 'mass')\n",
    "test_nodule       = os.path.join(test_dir, 'nodule')\n",
    "test_none         = os.path.join(test_dir, 'none')\n",
    "test_pneumothorax = os.path.join(test_dir, 'pneumothorax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training atelectasisat images: 400\n",
      "Total training effusion images: 400\n",
      "Total training infiltration images: 400\n",
      "Total training mass images: 200\n",
      "Total training nodule images: 300\n",
      "Total training no finding images: 400\n",
      "Total training pneumothorax images: 300\n"
     ]
    }
   ],
   "source": [
    "print('Total training atelectasisat images:', len(os.listdir(train_atelectasis)))\n",
    "print('Total training effusion images:', len(os.listdir(train_effusion)))\n",
    "print('Total training infiltration images:', len(os.listdir(train_infiltration)))\n",
    "print('Total training mass images:', len(os.listdir(train_mass)))\n",
    "print('Total training nodule images:', len(os.listdir(train_nodule)))\n",
    "print('Total training no finding images:', len(os.listdir(train_none)))\n",
    "print('Total training pneumothorax images:', len(os.listdir(train_pneumothorax)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total validation atelectasisat images: 100\n",
      "Total validation effusion images: 100\n",
      "Total validation infiltration images: 100\n",
      "Total validation mass images: 55\n",
      "Total validation nodule images: 70\n",
      "Total validation no finding images: 100\n",
      "Total validation pneumothorax images: 70\n"
     ]
    }
   ],
   "source": [
    "print('Total validation atelectasisat images:', len(os.listdir(val_atelectasis)))\n",
    "print('Total validation effusion images:', len(os.listdir(val_effusion)))\n",
    "print('Total validation infiltration images:', len(os.listdir(val_infiltration)))\n",
    "print('Total validation mass images:', len(os.listdir(val_mass)))\n",
    "print('Total validation nodule images:', len(os.listdir(val_nodule)))\n",
    "print('Total validation no finding images:', len(os.listdir(val_none)))\n",
    "print('Total validation pneumothorax images:', len(os.listdir(val_pneumothorax)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total test atelectasisat images: 101\n",
      "Total test effusion images: 100\n",
      "Total test infiltration images: 100\n",
      "Total test mass images: 55\n",
      "Total test nodule images: 70\n",
      "Total test no finding images: 100\n",
      "Total test pneumothorax images: 70\n"
     ]
    }
   ],
   "source": [
    "print('Total test atelectasisat images:', len(os.listdir(test_atelectasis)))\n",
    "print('Total test effusion images:', len(os.listdir(test_effusion)))\n",
    "print('Total test infiltration images:', len(os.listdir(test_infiltration)))\n",
    "print('Total test mass images:', len(os.listdir(test_mass)))\n",
    "print('Total test nodule images:', len(os.listdir(test_nodule)))\n",
    "print('Total test no finding images:', len(os.listdir(test_none)))\n",
    "print('Total test pneumothorax images:', len(os.listdir(test_pneumothorax)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Build a CNN from scratch\n",
    "Build a shallow (2-4 convolution layers) CNN. You are free to choose any values you wish for the filter size(s), pooling window size(s), and activation function(s). Please use an input shape of `(150, 150, 3)`. Include a dense layer on top along with an appropriate output layer (number of neurons and activation function). Be sure to also include the `model.compile` function with an appropriate choice of loss function and performance metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the image generator\n",
    "Using the `ImageDataGenerator` function, create `train_datagen` and `test_datagen` generators that rescale the images appropriately. Then define a training set generator and validation set generator using the generators `train_datagen` and `test_datagen` and the `.flow_from_directory` function. Specify the `target_size` (it should match the input size above), set the `batch_size` to 20 and choose an appropriate `class_mode`.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2400 images belonging to 7 classes.\n",
      "Found 595 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this code chunck to view the shapes of one batch of your training images and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data batch shape: (20, 150, 150, 3)\n",
      "labels batch shape: (20, 7)\n"
     ]
    }
   ],
   "source": [
    "for data_batch, labels_batch in train_generator:\n",
    "    print('data batch shape:', data_batch.shape)\n",
    "    print('labels batch shape:', labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile your model\n",
    "Be sure to choose appropriate numbers for the `steps_per_epoch` and `validation_steps` parameters. If one of the numbers is not a multiple of the batch size, round up to the nearest integer. Run this model for 30 epochs. Be sure to save your trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your model\n",
    "model.save('chest_1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot training and validation loss\n",
    "Plot the training and validation loss. Does the model seem to be overfitting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test accuracy\n",
    "Calculate and report the test set accuracy using the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = test_datagen.flow_from_directory(\n",
    "                 test_dir,\n",
    "                 target_size=(150, 150),\n",
    "                 batch_size=20,\n",
    "                 class_mode='categorical')\n",
    "\n",
    "test_loss, test_acc = model.evaluate_generator(test_generator, steps=30)\n",
    "print('test acc:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Using data augmentation\n",
    "Using the same architecture above, fit the CNN using data augmentation. You are free to choose the type of alterations made to the training images and the batch size (you should increase this for data augmentation). Be sure to include a `Dropout` layer before the first dense layer. Run this model for 30 epochs. Be sure to save your trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your model\n",
    "model.save('chest_2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot training and validation loss\n",
    "Plot the training and validation loss. Does the model seem to be overfitting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test accuracy\n",
    "Calculate and report the test set accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Using a pre-trained CNN without data augmentation\n",
    "\n",
    "Use one of the pre-trained models in Keras that has been trained using the Imagenet data set as a convolutional base. Extract features by running your training set through the base. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take this output and train a classifier. You may use the classifier from previous parts of this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your model\n",
    "model.save('chest_3.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot training and validation loss\n",
    "Plot the training and validation loss. Does the model seem to be overfitting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test accuracy\n",
    "Calculate and report the test set accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Summarize results\n",
    "Summarize the results from the 3 models you built. Which model would you choose to make future predictions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. **Optional**: Data augmentation with pre-trained CNN\n",
    "If you would like to try cloud computing, you can build a CNN and use data augmentation along with a pre-trained network for classification. **You will need to use Google Cloud Platform to train this model**. Please follow the instructions on how to set up access to GPUs and run code from a Jupyter notebook. These instructions can be found on canvas and the course GitHub repository. Be sure to save your trained model.\n",
    "\n",
    "If you choose to do this, you will get 20 extra credit homework points. Homework #3 is worth 25 points, so you wouldn't have to do much work on that assignment to get all of your homework credits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your model\n",
    "model.save('chest_4.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot training and validation loss\n",
    "Plot the training and validation loss. Does the model seem to be overfitting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test accuracy\n",
    "Calculate and report the test set accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
